<!DOCTYPE html><html lang="en" data-theme="pastel" class="overflow-y-scroll"> <head><meta charset="UTF-8"><meta name="description" content="Research lab focused on interpretable representation learning and explainable AI"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/png" href="/favicon.png"><meta name="generator" content="Astro v4.16.19"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Nunito:wght@300;400;600;700&display=swap" rel="stylesheet"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"><title>Publications - sqIRL Lab</title><link rel="stylesheet" href="/_astro/events.BOHotzeb.css"></head> <body class="bg-base-200 min-h-screen">  <div class="bg-base-100 shadow-md sticky top-0 z-50"> <div class="max-w-[1000px] mx-auto px-4 flex items-center justify-between py-3"> <div class="dropdown lg:hidden"> <div tabindex="0" role="button" class="btn btn-ghost"> <i class="fas fa-bars"></i> </div> <ul tabindex="0" class="menu menu-sm dropdown-content mt-3 z-[1] p-2 shadow bg-base-100 rounded-box w-52"> <li> <a href="/" class=""> <i class="fas fa-home"></i> Home </a> </li><li> <a href="/people" class=""> <i class="fas fa-users"></i> People </a> </li><li> <a href="/events" class=""> <i class="fas fa-calendar"></i> Events </a> </li><li> <a href="/publications" class="active"> <i class="fas fa-book"></i> Publications </a> </li> </ul> </div> <a href="/" class="text-xl font-bold lg:hidden">sqIRL</a> <div role="tablist" class="tabs tabs-boxed hidden lg:flex mx-auto"> <a href="/" role="tab" class="tab "> <i class="fas fa-home mr-2"></i> Home </a><a href="/people" role="tab" class="tab "> <i class="fas fa-users mr-2"></i> People </a><a href="/events" role="tab" class="tab "> <i class="fas fa-calendar mr-2"></i> Events </a><a href="/publications" role="tab" class="tab tab-active"> <i class="fas fa-book mr-2"></i> Publications </a> </div> </div> </div> <div class="max-w-[1000px] mx-auto px-4 py-8"> <div class="mb-8"> <div class="divider font-bold text-lg opacity-60">2025</div> <div class="flex flex-col gap-4"> <a href="https://openreview.net/pdf?id=sVh3eQ642W" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="Parameterized synthetic text generation with simplestories" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Parameterized synthetic text generation with simplestories</h4><p class="opacity-80 mt-2 truncate">A dataset full of simple yet diverse stories; the MNIST for language</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">NeurIPS&#39;25</span></div></div></a><a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231225026979" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/saja.png" alt="A taxonomy of interpretation and explanation methods for capsule network architectures" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">A taxonomy of interpretation and explanation methods for capsule network architectures</h4><p class="opacity-80 mt-2 truncate">This paper presents a comprehensive taxonomy of interpretation and explanation methods developed for capsule network (capsnet) architectures, analyzing their mechanisms, applicability, and performance across diverse problem domains.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">Neurocomputing</span></div></div></a><a href="https://www.arxiv.org/pdf/2510.16820" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="Finding manifolds with bilinear autoencoders" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Finding manifolds with bilinear autoencoders</h4><p class="opacity-80 mt-2 truncate">Decomposing activations into sparse polynomials and using their geometry</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">NeurIPS&#39;25</span><div class="flex gap-1 flex-wrap justify-end"><span class="badge badge-primary badge-sm whitespace-nowrap">spotlight</span><span class="badge badge-primary badge-sm whitespace-nowrap">workshop</span></div></div></div></a><a href="https://arxiv.org/abs/2408.12936" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/fabian.jpg" alt="Smooth infomax - towards easier post-hoc interpretability" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Smooth infomax - towards easier post-hoc interpretability</h4><p class="opacity-80 mt-2 truncate">Sim makes post-hoc interpretability tools more effective through latent space constraints</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">ECML-PKDD&#39;25</span></div></div></a><a href="https://openreview.net/forum?id=TEmE9PSC65" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/benjamin.jpg" alt="Improving neural network accuracy by concurrently training with a twin network" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Improving neural network accuracy by concurrently training with a twin network</h4><p class="opacity-80 mt-2 truncate">We show the applicability of twin network augmentation on convolutional neural networks</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">ICLR&#39;25</span></div></div></a><a href="https://ieeexplore.ieee.org/abstract/document/10978444" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/fabian.jpg" alt="Label-efficient learning for radio frequency fingerprint identification" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Label-efficient learning for radio frequency fingerprint identification</h4><p class="opacity-80 mt-2 truncate">We introduce a label-efficient approach for radio frequency fingerprint identification, achieving competitive accuracy with up to 10x fewer labels.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">IEEE WCNC&#39;25</span></div></div></a><a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231224017983" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/saja.png" alt="Towards the characterization of representations learned via capsule-based network architectures" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Towards the characterization of representations learned via capsule-based network architectures</h4><p class="opacity-80 mt-2 truncate">This paper provides a systematic and principled study on the interpretability of capsule network (capsnet) representations, aiming to characterize the nature and structure of the learned features across diverse architectures and datasets</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">Neurocomputing</span></div></div></a><a href="https://link.springer.com/chapter/10.1007/978-3-031-74630-7_5#citeas" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/saja.png" alt="Analyzing the explanation and interpretation potential of matrix capsule networks" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Analyzing the explanation and interpretation potential of matrix capsule networks</h4><p class="opacity-80 mt-2 truncate">This study investigates the internal mechanisms of matrix capsule networks with the EM routing algorithm</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">ECML-PKDD</span><div class="flex gap-1 flex-wrap justify-end"><span class="badge badge-primary badge-sm whitespace-nowrap">workshop</span></div></div></div></a> </div> </div><div class="mb-8"> <div class="divider font-bold text-lg opacity-60">2024</div> <div class="flex flex-col gap-4"> <div class="card bg-base-100 shadow-md p-6"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="Compositionality unlocks deep interpretable models" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Compositionality unlocks deep interpretable models</h4><p class="opacity-80 mt-2 truncate">Introducing a global svd-like algorithm for multi-linear models.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">AAAI&#39;25</span><div class="flex gap-1 flex-wrap justify-end"><span class="badge badge-primary badge-sm whitespace-nowrap">workshop</span></div></div></div></div><a href="https://tdooms.github.io/research/bilinear" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="Bilinear MLPs enable weight-based mechanistic interpretability" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Bilinear MLPs enable weight-based mechanistic interpretability</h4><p class="opacity-80 mt-2 truncate">Using bilinear MLPs to reverse-engineer shallow MNIST and tiny stories models from their weights.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">ICLR&#39;25</span><div class="flex gap-1 flex-wrap justify-end"><span class="badge badge-primary badge-sm whitespace-nowrap">spotlight</span></div></div></div></a><a href="https://arxiv.org/pdf/2409.15849" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/benjamin.jpg" alt="Twin network augmentation" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Twin network augmentation</h4><p class="opacity-80 mt-2 truncate">A novel training strategy for improved spiking neural networks and efficient weight quantization.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">arXiv</span></div></div></a><a href="https://tdooms.github.io/research/tokenized" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="Tokenized SAEs: disentangling SAE reconstructions" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Tokenized SAEs: disentangling SAE reconstructions</h4><p class="opacity-80 mt-2 truncate">We use a per-token bias in SAEs to separate token reconstructions from interesting features.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">ICML&#39;24</span><div class="flex gap-1 flex-wrap justify-end"><span class="badge badge-primary badge-sm whitespace-nowrap">workshop</span></div></div></div></a><a href="https://tdooms.github.io/research/bilinear" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="Weight-based decomposition: a case for bilinear MLPs" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Weight-based decomposition: a case for bilinear MLPs</h4><p class="opacity-80 mt-2 truncate">Introducing bilinear MLPs as a new approach to weight-based interpretability.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">ICML&#39;24</span><div class="flex gap-1 flex-wrap justify-end"><span class="badge badge-primary badge-sm whitespace-nowrap">workshop</span></div></div></div></a><a href="https://doi.org/10.1109/WHISPERS61460.2023.10430726" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/salma.jpg" alt="A contrastive learning method for multi-label predictors on hyperspectral images" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">A contrastive learning method for multi-label predictors on hyperspectral images</h4><p class="opacity-80 mt-2 truncate">Self-supervised contrastive learning for multi-label hyperspectral image classification</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">WHISPERS</span></div></div></a> </div> </div><div class="mb-8"> <div class="divider font-bold text-lg opacity-60">2023</div> <div class="flex flex-col gap-4"> <a href="https://doi.org/10.3390/rs15245656" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/salma.jpg" alt="Training methods of multi-label prediction classifiers for hyperspectral remote sensing images" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Training methods of multi-label prediction classifiers for hyperspectral remote sensing images</h4><p class="opacity-80 mt-2 truncate">A deep learning model for hyperspectral remote sensing, shifting from traditional single-label, pixel-level classification to multi-label, patch-level analysis</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">Remote Sensing</span></div></div></a><a href="https://tdooms.github.io/research/trifecta" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/thomas.jpg" alt="The trifecta: three techniques for deeper forward-forward networks" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">The trifecta: three techniques for deeper forward-forward networks</h4><p class="opacity-80 mt-2 truncate">Three techniques to significantly improve the forward-forward algorithm. We achieve 84% on CIFAR-10.</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">TMLR</span></div></div></a><a href="https://www.sciencedirect.com/science/article/pii/S0950705122007300" target="_blank" rel="noopener noreferrer" class="card bg-base-100 shadow-md hover:shadow-xl transition-shadow p-6 block"><div class="flex items-start justify-between gap-6"><div class="flex items-start gap-4 flex-grow min-w-0"><img src="/saja.png" alt="Gated recurrent unit with multilingual universal sentence encoder for arabic aspect-based sentiment analysis" class="w-16 h-16 object-cover rounded-lg flex-shrink-0"><div class="flex-grow min-w-0"><h4 class="text-xl font-bold truncate">Gated recurrent unit with multilingual universal sentence encoder for arabic aspect-based sentiment analysis</h4><p class="opacity-80 mt-2 truncate">This study presents a deep learning model for arabic aspect-based sentiment analysis (ABSA) using gated recurrent units (gru) combined with features from the multilingual universal sentence encoder (muse)</p></div></div><div class="flex flex-col items-end gap-2 flex-shrink-0"><span class="text-sm font-semibold whitespace-nowrap">Knowledge Based Systems</span></div></div></a> </div> </div> </div>  </body></html>