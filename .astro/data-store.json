[["Map",1,2,9,10,86,87,299,300,311,312,409,410],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.1","content-config-digest","e85c5da6148dd422","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://sqirllab.github.io\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","people",["Map",11,12,21,22,30,31,40,41,49,50,59,60,68,69,77,78],"benjamin",{"id":11,"data":13,"filePath":19,"digest":20},{"name":14,"status":15,"specialty":16,"image":17,"link":18},"Benjamin Vandersmissen","PhD student","Representations and lottery ticket hypothesis","benjamin.jpg","https://scholar.google.com/citations?user=pfgVNMUAAAAJ&hl=en","src/content/people/benjamin.json","5463b1cb0277467e","fabian",{"id":21,"data":23,"filePath":28,"digest":29},{"name":24,"status":15,"specialty":25,"image":26,"link":27},"Fabian Denoodt","Trustworthy and reliable learning","fabian.jpg","https://fdenoodt.github.io/","src/content/people/fabian.json","7a54184d98782890","jose",{"id":30,"data":32,"filePath":38,"digest":39},{"name":33,"status":34,"specialty":35,"image":36,"link":37},"Jose Oramas","Professor","Model Interpretability and Explainability","jose.png","https://webserver.idlab.uantwerpen.be/~joramasmogrovejo/","src/content/people/jose.json","41f7721094eeb240","peter",{"id":40,"data":42,"filePath":47,"digest":48},{"name":43,"status":15,"specialty":44,"image":45,"link":46},"Peter Kirby","Binary Hyperdimensional Computing","peter.jpg","https://www.uantwerpen.be/en/staff/peter-kirby_27404/","src/content/people/peter.json","45121b3f9443f231","renata",{"id":49,"data":51,"filePath":57,"digest":58},{"name":52,"status":53,"specialty":54,"image":55,"link":56},"Renata Turke≈°","Postdoctoral researcher","Topological data analysis","renata.png","https://renata-turkes.github.io","src/content/people/renata.json","31038571fc01c248","saja",{"id":59,"data":61,"filePath":66,"digest":67},{"name":62,"status":15,"specialty":63,"image":64,"link":65},"Saja Tawalbeh","Explainable artificial intelligence","saja.png","https://stawalbeh.github.io/STawalbeh/","src/content/people/saja.json","7b704b9f71cf27e7","salma",{"id":68,"data":70,"filePath":75,"digest":76},{"name":71,"status":15,"specialty":72,"image":73,"link":74},"Salma Haidar","Hyperspectral image analysis","salma.jpg","https://www.salmahaidar.com/","src/content/people/salma.json","86f015ffd9df6b48","thomas",{"id":77,"data":79,"filePath":84,"digest":85},{"name":80,"status":15,"specialty":81,"image":82,"link":83},"Thomas Dooms","Weight-based interpretability","thomas.jpg","https://tdooms.github.io/","src/content/people/thomas.json","172ff8224d2951fd","publications",["Map",88,89,99,100,112,113,123,124,134,135,144,145,155,156,166,167,176,177,187,188,197,198,208,209,217,218,228,229,238,239,249,250,260,261,268,269,279,280,290,291],"arabic-absa",{"id":88,"data":90,"filePath":97,"digest":98},{"title":91,"date":92,"conference":93,"tags":94,"link":95,"image":64,"description":96},"Gated Recurrent Unit with Multilingual Universal Sentence Encoder for Arabic Aspect-Based Sentiment Analysis","2023/02/01","Knowledge Based Systems",[],"https://www.sciencedirect.com/science/article/pii/S0950705122007300","This study presents a deep learning model for Arabic Aspect-Based Sentiment Analysis (ABSA) using Gated Recurrent Units (GRU) combined with features from the Multilingual Universal Sentence Encoder (MUSE)","src/content/publications/arabic-absa.json","e78342a5e030c749","bilinear-autoencoders",{"id":99,"data":101,"filePath":110,"digest":111},{"title":102,"date":103,"conference":104,"tags":105,"link":108,"image":82,"description":109},"Finding manifolds with bilinear autoencoders","2025/10/01","NeurIPS'25",[106,107],"spotlight","workshop","https://www.arxiv.org/pdf/2510.16820","Decomposing activations into sparse polynomials and using their geometry","src/content/publications/bilinear-autoencoders.json","070632f83d3b8ac1","bilinear-mlps",{"id":112,"data":114,"filePath":121,"digest":122},{"title":115,"date":116,"conference":117,"tags":118,"link":119,"image":82,"description":120},"Bilinear MLPs enable weight-based mechanistic interpretability","2024/10/01","ICLR'25",[106],"https://tdooms.github.io/research/bilinear","Using bilinear MLPs to reverse-engineer shallow MNIST and Tiny Stories models from their weights.","src/content/publications/bilinear-mlps.json","7816394688a86612","capsnet-representations",{"id":123,"data":125,"filePath":132,"digest":133},{"title":126,"date":127,"conference":128,"tags":129,"link":130,"image":64,"description":131},"Towards the Characterization of Representations Learned via Capsule-Based Network Architectures","2025/02/01","Neurocomputing",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231224017983","This paper provides a systematic and principled study on the interpretability of Capsule Network (CapsNet) representations, aiming to characterize the nature and structure of the learned features across diverse architectures and datasets","src/content/publications/capsnet-representations.json","ea4312975d82c3d0","compositionality",{"id":134,"data":136,"filePath":142,"digest":143},{"title":137,"date":138,"conference":139,"tags":140,"image":82,"description":141},"Compositionality unlocks deep interpretable models","2024/12/01","AAAI'25",[107],"Introducing a global SVD-like algorithm for multi-linear models.","src/content/publications/compositionality.json","dc581920f7142f6c","hsi-contrastive",{"id":144,"data":146,"filePath":153,"digest":154},{"title":147,"date":148,"conference":149,"tags":150,"link":151,"image":73,"description":152},"A Contrastive Learning Method for Multi-Label Predictors on Hyperspectral Images","2024/02/01","WHISPERS",[],"https://doi.org/10.1109/WHISPERS61460.2023.10430726","Self-supervised contrastive learning for multi-label hyperspectral image classification","src/content/publications/hsi-contrastive.json","00db7829eb1f33b9","hsi-multilabel",{"id":155,"data":157,"filePath":164,"digest":165},{"title":158,"date":159,"conference":160,"tags":161,"link":162,"image":73,"description":163},"Training Methods of Multi-Label Prediction Classifiers for Hyperspectral Remote Sensing Images","2023/12/01","Remote Sensing",[],"https://doi.org/10.3390/rs15245656","A deep learning model for hyperspectral remote sensing, shifting from traditional single-label, pixel-level classification to multi-label, patch-level analysis","src/content/publications/hsi-multilabel.json","1a90715870c35626","matrix-capsnet",{"id":166,"data":168,"filePath":174,"digest":175},{"title":169,"date":127,"conference":170,"tags":171,"link":172,"image":64,"description":173},"Analyzing the Explanation and Interpretation Potential of Matrix Capsule Networks","ECML-PKDD",[107],"https://link.springer.com/chapter/10.1007/978-3-031-74630-7_5#citeas","This study investigates the internal mechanisms of Matrix Capsule Networks with the EM Routing algorithm","src/content/publications/matrix-capsnet.json","c318782d8e07431d","radio-fingerprint",{"id":176,"data":178,"filePath":185,"digest":186},{"title":179,"date":180,"conference":181,"tags":182,"link":183,"image":26,"description":184},"Label-efficient learning for radio frequency fingerprint identification","2025/03/01","IEEE WCNC'25",[],"https://ieeexplore.ieee.org/abstract/document/10978444","We introduce a label-efficient approach for Radio Frequency Fingerprint Identification, achieving competitive accuracy with up to 10x fewer labels.","src/content/publications/radio-fingerprint.json","342b2c99bcf6afce","simplestories",{"id":187,"data":189,"filePath":195,"digest":196},{"title":190,"date":191,"conference":104,"tags":192,"link":193,"image":82,"description":194},"Parameterized Synthetic Text Generation with SimpleStories","2025/11/01",[],"https://openreview.net/pdf?id=sVh3eQ642W","A dataset full of simple yet diverse stories; the MNIST for language","src/content/publications/simplestories.json","1a094b6629126a32","tokenized-saes",{"id":197,"data":199,"filePath":206,"digest":207},{"title":200,"date":201,"conference":202,"tags":203,"link":204,"image":82,"description":205},"Tokenized SAEs: Disentangling SAE Reconstructions","2024/06/01","ICML'24",[107],"https://tdooms.github.io/research/tokenized","We use a per-token bias in SAEs to separate token reconstructions from interesting features.","src/content/publications/tokenized-saes.json","f5689c0034819c63","taxonomy-capsnet",{"id":208,"data":210,"filePath":215,"digest":216},{"title":211,"date":191,"conference":128,"tags":212,"link":213,"image":64,"description":214},"A Taxonomy of Interpretation and Explanation Methods for Capsule Network Architectures",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231225026979","This paper presents a comprehensive taxonomy of interpretation and explanation methods developed for Capsule Network (CapsNet) architectures, analyzing their mechanisms, applicability, and performance across diverse problem domains.","src/content/publications/taxonomy-capsnet.json","2a8ca3126666da83","trifecta",{"id":217,"data":219,"filePath":226,"digest":227},{"title":220,"date":221,"conference":222,"tags":223,"link":224,"image":82,"description":225},"The Trifecta: Three techniques for deeper Forward-Forward networks","2023/11/01","TMLR",[],"https://tdooms.github.io/research/trifecta","Three techniques to significantly improve the Forward-Forward algorithm. We achieve 84% on CIFAR-10.","src/content/publications/trifecta.json","828a58fc61fa6322","twin-network-cnn",{"id":228,"data":230,"filePath":236,"digest":237},{"title":231,"date":232,"conference":117,"tags":233,"link":234,"image":17,"description":235},"Improving neural network accuracy by concurrently training with a twin network","2025/04/01",[],"https://openreview.net/forum?id=TEmE9PSC65","We show the applicability of twin network augmentation on convolutional neural networks","src/content/publications/twin-network-cnn.json","0d376d92ff975f98","smooth-infomax",{"id":238,"data":240,"filePath":247,"digest":248},{"title":241,"date":242,"conference":243,"tags":244,"link":245,"image":26,"description":246},"Smooth InfoMax - Towards Easier Post-Hoc Interpretability","2025/09/01","ECML-PKDD'25",[],"https://arxiv.org/abs/2408.12936","SIM makes post-hoc interpretability tools more effective through latent space constraints","src/content/publications/smooth-infomax.json","ecf8843894302409","twin-network-snn",{"id":249,"data":251,"filePath":258,"digest":259},{"title":252,"date":253,"conference":254,"tags":255,"link":256,"image":17,"description":257},"Twin Network Augmentation","2024/09/01","arXiv",[],"https://arxiv.org/pdf/2409.15849","A Novel Training Strategy for Improved Spiking Neural Networks and Efficient Weight Quantization.","src/content/publications/twin-network-snn.json","eb8ff15a76ecebbd","weight-based-decomposition",{"id":260,"data":262,"filePath":266,"digest":267},{"title":263,"date":201,"conference":202,"tags":264,"link":119,"image":82,"description":265},"Weight-based Decomposition: A Case for Bilinear MLPs",[107],"Introducing bilinear MLPs as a new approach to weight-based interpretability.","src/content/publications/weight-based-decomposition.json","f81a5cdaefd2f9de","coherence-explanations",{"id":268,"data":270,"filePath":277,"digest":278},{"title":271,"date":272,"conference":273,"tags":274,"link":275,"image":17,"description":276},"On the coherency of quantitative evaluation of visual explanations","2024/04/01","CVIU vol. 241",[],"https://doi.org/10.1016/j.cviu.2024.103934","Measuring the correlation between different quantitative evaluation metrics for visual explanations.","src/content/publications/coherence-explanations.json","da31296bc8404f3d","model-compression",{"id":279,"data":281,"filePath":288,"digest":289},{"title":282,"date":283,"conference":284,"tags":285,"link":286,"image":17,"description":287},"Deep learning model compression for resource efficient activity recognition on edge devices: a case study","2024/02/27","VISAPP'24",[],"https://repository.uantwerpen.be/docman/irua/666490motoM98","This paper presents an approach to adapt an existing activity recognition model for efficient deployment on edge devices.","src/content/publications/model-compression.json","686d35973cb60458","action-recognition",{"id":290,"data":292,"filePath":297,"digest":298},{"title":293,"date":283,"conference":284,"tags":294,"link":295,"image":17,"description":296},"Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector",[],"https://repository.uantwerpen.be/docman/irua/3d6ebamotoMe4","This study investigates the applicability of established action recognition methodologies in the dynamic setting of the construction sector.","src/content/publications/action-recognition.json","668528a1c5a528ca","home",["Map",301,302],"main",{"id":301,"data":303,"filePath":309,"digest":310},{"title":304,"subtitle":305,"description":306,"email":307,"logo":308},"sqIRL","Interpretable Representation Learning","The Interpretable Representation Learning lab, sqIRL, at the University of Antwerp pursues fundamental research at the intersection of machine learning and interpretability/explainability. Our research focuses on the inner-workings of AI systems and the learning processes that produce them. We aim to develop AI systems that are interpretable/explainable and more efficient in their use of data and computational resources.","jose.oramasmogrovejo@uantwerpen.be","/logo.png","src/content/home/main.json","64c87d672340e3cb","events",["Map",313,314,322,323,330,331,338,339,347,348,356,357,365,366,374,375,382,383,391,392,400,401],"acrai-research-day",{"id":313,"data":315,"filePath":320,"digest":321},{"title":316,"date":317,"link":318,"image":73,"description":319},"Talk @ ACRAI Research Day","2025/02/21","https://www.uantwerpen.be/en/research-groups/acrai/","Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging","src/content/events/acrai-research-day.json","43c3f298c9329f0c","becode",{"id":322,"data":324,"filePath":328,"digest":329},{"title":325,"date":116,"link":326,"image":64,"description":327},"Talk @ BeCode","https://becode.org/","General presentation about explainability","src/content/events/becode.json","b704f32d0e63c0d0","clusity",{"id":330,"data":332,"filePath":336,"digest":337},{"title":333,"date":334,"link":335,"image":64,"description":327},"Talk @ Clusity","2023/06/01","https://www.clusity.be/","src/content/events/clusity.json","268cb0d7cd2ba870","flanders-ai-day",{"id":338,"data":340,"filePath":345,"digest":346},{"title":341,"date":342,"link":343,"image":82,"description":344},"Talk @ Flanders AI Day","2024/10/14","https://docs.google.com/presentation/d/1PdcHm0bgwIu3yhy6oWkwL1-fDGTPzTiyUilydognLlw/edit?usp=sharing","A swift introduction to weight-based interpretability.","src/content/events/flanders-ai-day.json","06b5b0d7783a0ace","kekule-cycle",{"id":347,"data":349,"filePath":354,"digest":355},{"title":350,"date":351,"link":352,"image":36,"description":353},"Talk @ Kekule Cycle XXI","2025/10/14","https://www.kvcv.be/nl/activiteiten-en-nieuws/kalender/676-quid-quantum-and-ai","An accessible introduction to representation learning and interpretability","src/content/events/kekule-cycle.json","5989a88e73d4f3db","vaia-webinar",{"id":356,"data":358,"filePath":363,"digest":364},{"title":359,"date":360,"link":361,"image":73,"description":362},"Webinar @ VAIA - Flanders AI EDIH HSI Talk","2025/09/29","https://www.vaia.be/","Hyperspectral Imaging and Machine Learning: Decoding the Spectrum for Advanced Data Analysis","src/content/events/vaia-webinar.json","70b281a9490e6153","wids",{"id":365,"data":367,"filePath":372,"digest":373},{"title":368,"date":369,"link":370,"image":64,"description":371},"Talk @ Women in Data Science (WiDS)","2024/03/01","https://www.widsconference.org/","Analyzing Representations Learned via Capsule Neural Networks. A systematic and principled study towards assessing the interpretability of Capsule networks","src/content/events/wids.json","934141e8fa1868c5","visapp24",{"id":374,"data":376,"filePath":380,"digest":381},{"title":377,"date":283,"link":378,"image":17,"description":379},"Talk @ VisAPP'24","https://visapp.scitevents.org/","Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector.","src/content/events/visapp24.json","fed64b813f0b8092","dataset-distillation-vaia",{"id":382,"data":384,"filePath":389,"digest":390},{"title":385,"date":386,"link":387,"image":17,"description":388},"Webinar@Dataset Distillation - A Gentle Introduction","2025/07/15","https://www.vaia.be/en/courses/dataset-distillation-a-gentle-introduction","Get familiar with the standard dataset distillation techniques, and gain familiarity with uses cases that could benefit from it.","src/content/events/dataset-distillation-vaia.json","7f6e4e2768feca5e","efficientml",{"id":391,"data":393,"filePath":398,"digest":399},{"title":394,"date":395,"link":396,"image":17,"description":397},"Talk@Efficient ML Reading Group","2025/06/30","https://www.youtube.com/watch?v=rB2_SZIQUd0","Twin Network Augmentation for Convolutional Neural Networks.","src/content/events/efficientml.json","344416d884bcffd7","flanders-ai-2023",{"id":400,"data":402,"filePath":407,"digest":408},{"title":403,"date":404,"link":405,"image":17,"description":406},"Talk@Flanders AI Day - Workshop on Advances in Responsible AI","2023/10/16","https://www.flandersairesearch.be/en/research/research-day","Presentation on coherence between different evaluation metrics for visual explanations.","src/content/events/flanders-ai-2023.json","29f853d0238d6a70","news",["Map",411,412,418,419,425,426,432,433,441,442,448,449,455,456,462,463,469,470,476,477],"2024-03-wids",{"id":411,"data":413,"filePath":416,"digest":417},{"date":369,"title":414,"description":415},"Event","Co-organized a Women in Data event.","src/content/news/2024-03-wids.json","5f73b4a7faa959ae","2024-09-workshop",{"id":418,"data":420,"filePath":423,"digest":424},{"date":253,"title":421,"description":422},"Workshop","Co-organized the AIMLAI Workshop held in conjunction with ECML-PKDD'24.","src/content/news/2024-09-workshop.json","7e2ee729f377a06a","2024-10-peter",{"id":425,"data":427,"filePath":430,"digest":431},{"date":116,"title":428,"description":429},"New member","sqIRL welcomes Peter to the lab.","src/content/news/2024-10-peter.json","1cf43d89dbfe72a9","2024-10-tmlr",{"id":432,"data":434,"filePath":439,"digest":440},{"date":435,"title":436,"description":437,"link":438},"2024/10/02","Paper accepted","Thomas' work on deeper forward-forward networks got published at TMLR.","https://openreview.net/forum?id=a7KP5uo0Fp","src/content/news/2024-10-tmlr.json","14183511984ccb85","2024-12-neurocomputing",{"id":441,"data":443,"filePath":446,"digest":447},{"date":138,"title":436,"description":444,"link":445},"Saja's paper on the interpretability of Capsule Networks was accepted at the journal of Neurocomputing.","https://arxiv.org/abs/2305.05349","src/content/news/2024-12-neurocomputing.json","3cfb1c6745a2798b","2025-01-iclr",{"id":448,"data":450,"filePath":453,"digest":454},{"date":451,"title":436,"description":452},"2025/01/01","Two papers accepted at ICLR'25 on Twin Network Augmentation and Interpretability via Bilinear MLPs.","src/content/news/2025-01-iclr.json","39e899cda47d4191","2025-06-ecml",{"id":455,"data":457,"filePath":460,"digest":461},{"date":458,"title":436,"description":459},"2025/06/01","Two papers accepted at ECML-PKDD'25 on Smooth-InfoMax and Interpretability of SNNs.","src/content/news/2025-06-ecml.json","1aec7e1098ae188d","2025-09-renata",{"id":462,"data":464,"filePath":467,"digest":468},{"date":242,"title":428,"description":465,"link":466},"sqIRL welcomes Renata to the lab.","https://renata-turkes.github.io/","src/content/news/2025-09-renata.json","d19570370e7284c3","2025-10-neurocomputing-hdc",{"id":469,"data":471,"filePath":474,"digest":475},{"date":103,"title":436,"description":472,"link":473},"One paper accepted at Neurocomputing on Interpretable HDC Classifiers.","https://doi.org/10.1016/j.neucom.2025.131643","src/content/news/2025-10-neurocomputing-hdc.json","02a93ace17aa8479","2025-11-neurocomputing",{"id":476,"data":478,"filePath":480,"digest":481},{"date":191,"title":436,"description":479,"link":213},"Saja's paper on positioning a taxonomy of interpretation and explanation methods for Capsule Networks was accepted in the journal Neurocomputing.","src/content/news/2025-11-neurocomputing.json","9aa17e92db1f2ddb"]