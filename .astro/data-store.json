[["Map",1,2,9,10,86,87,268,269,342,343,413,414],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.0","content-config-digest","2b8cf03ca22a0ab0","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://sqirllab.github.io\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","people",["Map",11,12,21,22,30,31,40,41,49,50,58,59,68,69,77,78],"benjamin",{"id":11,"data":13,"filePath":19,"digest":20},{"name":14,"status":15,"specialty":16,"image":17,"link":18},"Benjamin Versmissen","PhD student","Representations and lottery ticket hypothesis","benjamin.jpg","https://scholar.google.com/citations?user=pfgVNMUAAAAJ&hl=en","src/content/people/benjamin.json","a17e804072ed57fb","fabian",{"id":21,"data":23,"filePath":28,"digest":29},{"name":24,"status":15,"specialty":25,"image":26,"link":27},"Fabian Denoodt","Trustworthy and reliable learning","fabian.jpg","https://fdenoodt.github.io/","src/content/people/fabian.json","7a54184d98782890","jose",{"id":30,"data":32,"filePath":38,"digest":39},{"name":33,"status":34,"specialty":35,"image":36,"link":37},"Jose Oramas","Professor","Model Interpretability and Explainability","jose.png","https://webserver.idlab.uantwerpen.be/~joramasmogrovejo/","src/content/people/jose.json","41f7721094eeb240","salma",{"id":40,"data":42,"filePath":47,"digest":48},{"name":43,"status":15,"specialty":44,"image":45,"link":46},"Salma Haidar","Hyperspectral image analysis","salma.jpg","https://www.salmahaidar.com/","src/content/people/salma.json","037542832bbb6f12","peter",{"id":49,"data":51,"filePath":56,"digest":57},{"name":52,"status":15,"specialty":53,"image":54,"link":55},"Peter Kirby","Binary Hyperdimensional Computing","peter.jpg","https://www.uantwerpen.be/en/staff/peter-kirby_27404/","src/content/people/peter.json","4d7da9118133691c","renata",{"id":58,"data":60,"filePath":66,"digest":67},{"name":61,"status":62,"specialty":63,"image":64,"link":65},"Renata Turke≈°","Postdoctoral researcher","Topological data analysis","renata.png","https://renata-turkes.github.io","src/content/people/renata.json","31038571fc01c248","saja",{"id":68,"data":70,"filePath":75,"digest":76},{"name":71,"status":15,"specialty":72,"image":73,"link":74},"Saja Tawalbeh","Explainable artificial intelligence","saja.png","https://stawalbeh.github.io/STawalbeh/","src/content/people/saja.json","7b704b9f71cf27e7","thomas",{"id":77,"data":79,"filePath":84,"digest":85},{"name":80,"status":15,"specialty":81,"image":82,"link":83},"Thomas Dooms","Weight-based interpretability","thomas.jpg","https://tdooms.github.io/","src/content/people/thomas.json","172ff8224d2951fd","publications",["Map",88,89,99,100,112,113,123,124,134,135,144,145,155,156,166,167,176,177,187,188,197,198,208,209,219,220,228,229,238,239,249,250,260,261],"arabic-absa",{"id":88,"data":90,"filePath":97,"digest":98},{"title":91,"date":92,"conference":93,"tags":94,"link":95,"image":73,"description":96},"Gated Recurrent Unit with Multilingual Universal Sentence Encoder for Arabic Aspect-Based Sentiment Analysis","2023/02/01","Knowledge Based Systems",[],"https://www.sciencedirect.com/science/article/pii/S0950705122007300","This study presents a deep learning model for Arabic Aspect-Based Sentiment Analysis (ABSA) using Gated Recurrent Units (GRU) combined with features from the Multilingual Universal Sentence Encoder (MUSE)","src/content/publications/arabic-absa.json","c571ac58bffe37ef","bilinear-autoencoders",{"id":99,"data":101,"filePath":110,"digest":111},{"title":102,"date":103,"conference":104,"tags":105,"link":108,"image":82,"description":109},"Finding manifolds with bilinear autoencoders","2025/10/01","NeurIPS'25",[106,107],"spotlight","workshop","https://www.arxiv.org/pdf/2510.16820","Decomposing activations into sparse polynomials and using their geometry","src/content/publications/bilinear-autoencoders.json","070632f83d3b8ac1","bilinear-mlps",{"id":112,"data":114,"filePath":121,"digest":122},{"title":115,"date":116,"conference":117,"tags":118,"link":119,"image":82,"description":120},"Bilinear MLPs enable weight-based mechanistic interpretability","2024/10/01","ICLR'25",[106],"https://tdooms.github.io/research/bilinear","Using bilinear MLPs to reverse-engineer shallow MNIST and Tiny Stories models from their weights.","src/content/publications/bilinear-mlps.json","7816394688a86612","capsnet-representations",{"id":123,"data":125,"filePath":132,"digest":133},{"title":126,"date":127,"conference":128,"tags":129,"link":130,"image":73,"description":131},"Towards the Characterization of Representations Learned via Capsule-Based Network Architectures","2025/02/01","Neurocomputing",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231224017983","This paper provides a systematic and principled study on the interpretability of Capsule Network (CapsNet) representations, aiming to characterize the nature and structure of the learned features across diverse architectures and datasets","src/content/publications/capsnet-representations.json","6fe03616fd116249","compositionality",{"id":134,"data":136,"filePath":142,"digest":143},{"title":137,"date":138,"conference":139,"tags":140,"image":82,"description":141},"Compositionality unlocks deep interpretable models","2024/12/01","AAAI'25",[107],"Introducing a global SVD-like algorithm for multi-linear models.","src/content/publications/compositionality.json","dc581920f7142f6c","hsi-contrastive",{"id":144,"data":146,"filePath":153,"digest":154},{"title":147,"date":148,"conference":149,"tags":150,"link":151,"image":45,"description":152},"A Contrastive Learning Method for Multi-Label Predictors on Hyperspectral Images","2024/02/01","WHISPERS",[],"https://doi.org/10.1109/WHISPERS61460.2023.10430726","Self-supervised contrastive learning for multi-label hyperspectral image classification","src/content/publications/hsi-contrastive.json","8db813b54a35afb7","hsi-multilabel",{"id":155,"data":157,"filePath":164,"digest":165},{"title":158,"date":159,"conference":160,"tags":161,"link":162,"image":45,"description":163},"Training Methods of Multi-Label Prediction Classifiers for Hyperspectral Remote Sensing Images","2023/12/01","Remote Sensing",[],"https://doi.org/10.3390/rs15245656","A deep learning model for hyperspectral remote sensing, shifting from traditional single-label, pixel-level classification to multi-label, patch-level analysis","src/content/publications/hsi-multilabel.json","9cc3ca49f178ffc3","matrix-capsnet",{"id":166,"data":168,"filePath":174,"digest":175},{"title":169,"date":127,"conference":170,"tags":171,"link":172,"image":73,"description":173},"Analyzing the Explanation and Interpretation Potential of Matrix Capsule Networks","ECML-PKDD",[107],"https://link.springer.com/chapter/10.1007/978-3-031-74630-7_5#citeas","This study investigates the internal mechanisms of Matrix Capsule Networks with the EM Routing algorithm","src/content/publications/matrix-capsnet.json","e676b9e791e84eda","radio-fingerprint",{"id":176,"data":178,"filePath":185,"digest":186},{"title":179,"date":180,"conference":181,"tags":182,"link":183,"image":26,"description":184},"Label-efficient learning for radio frequency fingerprint identification","2025/03/01","IEEE WCNC'25",[],"https://ieeexplore.ieee.org/abstract/document/10978444","We introduce a label-efficient approach for Radio Frequency Fingerprint Identification, achieving competitive accuracy with up to 10x fewer labels.","src/content/publications/radio-fingerprint.json","342b2c99bcf6afce","simplestories",{"id":187,"data":189,"filePath":195,"digest":196},{"title":190,"date":191,"conference":104,"tags":192,"link":193,"image":82,"description":194},"Parameterized Synthetic Text Generation with SimpleStories","2025/11/01",[],"https://openreview.net/pdf?id=sVh3eQ642W","A dataset full of simple yet diverse stories; the MNIST for language","src/content/publications/simplestories.json","1a094b6629126a32","smooth-infomax",{"id":197,"data":199,"filePath":206,"digest":207},{"title":200,"date":201,"conference":202,"tags":203,"link":204,"image":26,"description":205},"Smooth InfoMax - Towards Easier Post-Hoc Interpretability","2025/09/01","ECML-PKDD'25",[],"https://arxiv.org/abs/2408.12936","SIM makes post-hoc interpretability tools more effective through latent space constraints","src/content/publications/smooth-infomax.json","ecf8843894302409","tokenized-saes",{"id":208,"data":210,"filePath":217,"digest":218},{"title":211,"date":212,"conference":213,"tags":214,"link":215,"image":82,"description":216},"Tokenized SAEs: Disentangling SAE Reconstructions","2024/06/01","ICML'24",[107],"https://tdooms.github.io/research/tokenized","We use a per-token bias in SAEs to separate token reconstructions from interesting features.","src/content/publications/tokenized-saes.json","f5689c0034819c63","taxonomy-capsnet",{"id":219,"data":221,"filePath":226,"digest":227},{"title":222,"date":191,"conference":128,"tags":223,"link":224,"image":73,"description":225},"A Taxonomy of Interpretation and Explanation Methods for Capsule Network Architectures",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231225026979","This paper presents a comprehensive taxonomy of interpretation and explanation methods developed for Capsule Network (CapsNet) architectures, analyzing their mechanisms, applicability, and performance across diverse problem domains.","src/content/publications/taxonomy-capsnet.json","79287c5c05ef0660","twin-network-cnn",{"id":228,"data":230,"filePath":236,"digest":237},{"title":231,"date":232,"conference":117,"tags":233,"link":234,"image":17,"description":235},"Improving neural network accuracy by concurrently training with a twin network","2025/04/01",[],"https://openreview.net/forum?id=TEmE9PSC65","We show the applicability of twin network augmentation on convolutional neural networks","src/content/publications/twin-network-cnn.json","0d376d92ff975f98","trifecta",{"id":238,"data":240,"filePath":247,"digest":248},{"title":241,"date":242,"conference":243,"tags":244,"link":245,"image":82,"description":246},"The Trifecta: Three techniques for deeper Forward-Forward networks","2023/11/01","TMLR",[],"https://tdooms.github.io/research/trifecta","Three techniques to significantly improve the Forward-Forward algorithm. We achieve 84% on CIFAR-10.","src/content/publications/trifecta.json","828a58fc61fa6322","twin-network-snn",{"id":249,"data":251,"filePath":258,"digest":259},{"title":252,"date":253,"conference":254,"tags":255,"link":256,"image":17,"description":257},"Twin Network Augmentation","2024/09/01","arXiv",[],"https://arxiv.org/pdf/2409.15849","A Novel Training Strategy for Improved Spiking Neural Networks and Efficient Weight Quantization.","src/content/publications/twin-network-snn.json","eb8ff15a76ecebbd","weight-based-decomposition",{"id":260,"data":262,"filePath":266,"digest":267},{"title":263,"date":212,"conference":213,"tags":264,"link":119,"image":82,"description":265},"Weight-based Decomposition: A Case for Bilinear MLPs",[107],"Introducing bilinear MLPs as a new approach to weight-based interpretability.","src/content/publications/weight-based-decomposition.json","f81a5cdaefd2f9de","news",["Map",270,271,278,279,285,286,292,293,301,302,308,309,315,316,322,323,329,330,336,337],"2024-03-wids",{"id":270,"data":272,"filePath":276,"digest":277},{"date":273,"title":274,"description":275},"2024/03/01","Event","Co-organized a Women in Data event.","src/content/news/2024-03-wids.json","c95fecd232febf1e","2024-09-workshop",{"id":278,"data":280,"filePath":283,"digest":284},{"date":253,"title":281,"description":282},"Workshop","Co-organized the AIMLAI Workshop held in conjunction with ECML-PKDD'24.","src/content/news/2024-09-workshop.json","7e2ee729f377a06a","2024-10-peter",{"id":285,"data":287,"filePath":290,"digest":291},{"date":116,"title":288,"description":289},"New member","sqIRL welcomes Peter to the lab.","src/content/news/2024-10-peter.json","1cf43d89dbfe72a9","2024-10-tmlr",{"id":292,"data":294,"filePath":299,"digest":300},{"date":295,"title":296,"description":297,"link":298},"2024/10/02","Paper accepted","Thomas' work on deeper forward-forward networks got published at TMLR.","https://openreview.net/forum?id=a7KP5uo0Fp","src/content/news/2024-10-tmlr.json","14183511984ccb85","2024-12-neurocomputing",{"id":301,"data":303,"filePath":306,"digest":307},{"date":138,"title":296,"description":304,"link":305},"Saja's paper on the interpretability of Capsule Networks was accepted at the journal of Neurocomputing.","https://arxiv.org/abs/2305.05349","src/content/news/2024-12-neurocomputing.json","3cfb1c6745a2798b","2025-01-iclr",{"id":308,"data":310,"filePath":313,"digest":314},{"date":311,"title":296,"description":312},"2025/01/01","Two papers accepted at ICLR'25 on Twin Network Augmentation and Interpretability via Bilinear MLPs.","src/content/news/2025-01-iclr.json","39e899cda47d4191","2025-06-ecml",{"id":315,"data":317,"filePath":320,"digest":321},{"date":318,"title":296,"description":319},"2025/06/01","Two papers accepted at ECML-PKDD'25 on Smooth-InfoMax and Interpretability of SNNs.","src/content/news/2025-06-ecml.json","20725891fb9ae057","2025-09-renata",{"id":322,"data":324,"filePath":327,"digest":328},{"date":201,"title":288,"description":325,"link":326},"sqIRL welcomes Renata to the lab.","https://renata-turkes.github.io/","src/content/news/2025-09-renata.json","0eb33526f39298b3","2025-10-neurocomputing-hdc",{"id":329,"data":331,"filePath":334,"digest":335},{"date":103,"title":296,"description":332,"link":333},"One paper accepted at Neurocomputing on Interpretable HDC Classifiers.","https://doi.org/10.1016/j.neucom.2025.131643","src/content/news/2025-10-neurocomputing-hdc.json","bdac8a4e68572314","2025-11-neurocomputing",{"id":336,"data":338,"filePath":340,"digest":341},{"date":191,"title":296,"description":339,"link":224},"Saja's paper on positioning a taxonomy of interpretation and explanation methods for Capsule Networks was accepted in the journal Neurocomputing.","src/content/news/2025-11-neurocomputing.json","335f6d44811f9cb1","events",["Map",344,345,353,354,361,362,369,370,378,379,387,388,396,397,405,406],"acrai-research-day",{"id":344,"data":346,"filePath":351,"digest":352},{"title":347,"date":348,"link":349,"image":45,"description":350},"Talk @ ACRAI Research Day","2025/02/21","https://www.uantwerpen.be/en/research-groups/acrai/","Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging","src/content/events/acrai-research-day.json","d56083156ac1793f","becode",{"id":353,"data":355,"filePath":359,"digest":360},{"title":356,"date":116,"link":357,"image":73,"description":358},"Talk @ BeCode","https://becode.org/","General presentation about explainability","src/content/events/becode.json","b6ee757aed027d6e","clusity",{"id":361,"data":363,"filePath":367,"digest":368},{"title":364,"date":365,"link":366,"image":73,"description":358},"Talk @ Clusity","2023/06/01","https://www.clusity.be/","src/content/events/clusity.json","b9b7fdaee2515cc1","flanders-ai-day",{"id":369,"data":371,"filePath":376,"digest":377},{"title":372,"date":373,"link":374,"image":82,"description":375},"Talk @ Flanders AI Day","2024/10/14","https://docs.google.com/presentation/d/1PdcHm0bgwIu3yhy6oWkwL1-fDGTPzTiyUilydognLlw/edit?usp=sharing","A swift introduction to weight-based interpretability.","src/content/events/flanders-ai-day.json","06b5b0d7783a0ace","kekule-cycle",{"id":378,"data":380,"filePath":385,"digest":386},{"title":381,"date":382,"link":383,"image":36,"description":384},"Talk @ Kekule Cycle XXI","2025/10/14","https://www.kvcv.be/nl/activiteiten-en-nieuws/kalender/676-quid-quantum-and-ai","An accessible introduction to representation learning and interpretability","src/content/events/kekule-cycle.json","5ad02519681d97a6","vaia-webinar",{"id":387,"data":389,"filePath":394,"digest":395},{"title":390,"date":391,"link":392,"image":45,"description":393},"Webinar @ VAIA - Flanders AI EDIH HSI Talk","2025/09/29","https://www.vaia.be/","Hyperspectral Imaging and Machine Learning: Decoding the Spectrum for Advanced Data Analysis","src/content/events/vaia-webinar.json","7c0033050db28e53","visapp25",{"id":396,"data":398,"filePath":403,"digest":404},{"title":399,"date":400,"link":401,"image":17,"description":402},"Talk @ VisAPP'25","2025/02/27","https://visapp.scitevents.org/","Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector.","src/content/events/visapp25.json","f81595a9e6ae188a","wids",{"id":405,"data":407,"filePath":411,"digest":412},{"title":408,"date":273,"link":409,"image":73,"description":410},"Talk @ Women in Data Science (WiDS)","https://www.widsconference.org/","Analyzing Representations Learned via Capsule Neural Networks. A systematic and principled study towards assessing the interpretability of Capsule networks","src/content/events/wids.json","a79845eb786be31f","home",["Map",415,416],"main",{"id":415,"data":417,"filePath":423,"digest":424},{"title":418,"subtitle":419,"description":420,"email":421,"logo":422},"sqIRL","Interpretable Representation Learning","The Interpretable Representation Learning lab, sqIRL, at the University of Antwerp pursues fundamental research at the intersection of machine learning and interpretability/explainability. Our research focuses on the inner-workings of AI systems and the learning processes that produce them. We aim to develop AI systems that are interpretable/explainable and more efficient in their use of data and computational resources.","jose.oramasmogrovejo@uantwerpen.be","/logo.png","src/content/home/main.json","5c88db8097927a4c"]