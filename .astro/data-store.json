[["Map",1,2,9,10,86,87,300,301,398,399,471,472],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.2","content-config-digest","e85c5da6148dd422","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://sqirllab.github.io\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","people",["Map",11,12,21,22,31,32,40,41,50,51,59,60,68,69,77,78],"benjamin",{"id":11,"data":13,"filePath":19,"digest":20},{"name":14,"status":15,"specialty":16,"image":17,"link":18},"Benjamin Vandersmissen","PhD student","Representations and lottery ticket hypothesis","benjamin.jpg","https://scholar.google.com/citations?user=pfgVNMUAAAAJ&hl=en","src/content/people/benjamin.json","5463b1cb0277467e","jose",{"id":21,"data":23,"filePath":29,"digest":30},{"name":24,"status":25,"specialty":26,"image":27,"link":28},"Jose Oramas","Professor","Representation Learning and Interpretability","jose.png","https://idlab.uantwerpen.be/~joramasmogrovejo/","src/content/people/jose.json","422a134df86afd3b","peter",{"id":31,"data":33,"filePath":38,"digest":39},{"name":34,"status":15,"specialty":35,"image":36,"link":37},"Peter Kirby","Binary hyperdimensional computing","peter.jpg","https://www.uantwerpen.be/en/staff/peter-kirby_27404/","src/content/people/peter.json","89803df955ca2798","renata",{"id":40,"data":42,"filePath":48,"digest":49},{"name":43,"status":44,"specialty":45,"image":46,"link":47},"Renata Turke≈°","Postdoctoral researcher","Topological data analysis","renata.png","https://renata-turkes.github.io","src/content/people/renata.json","31038571fc01c248","saja",{"id":50,"data":52,"filePath":57,"digest":58},{"name":53,"status":15,"specialty":54,"image":55,"link":56},"Saja Tawalbeh","Explainable artificial intelligence","saja.png","https://stawalbeh.github.io/STawalbeh/","src/content/people/saja.json","7b704b9f71cf27e7","salma",{"id":59,"data":61,"filePath":66,"digest":67},{"name":62,"status":15,"specialty":63,"image":64,"link":65},"Salma Haidar","Hyperspectral image analysis","salma.jpg","https://www.salmahaidar.com/","src/content/people/salma.json","86f015ffd9df6b48","thomas",{"id":68,"data":70,"filePath":75,"digest":76},{"name":71,"status":15,"specialty":72,"image":73,"link":74},"Thomas Dooms","Weight-based interpretability","thomas.jpg","https://tdooms.github.io/","src/content/people/thomas.json","172ff8224d2951fd","arian",{"id":77,"data":79,"filePath":84,"digest":85},{"name":80,"status":15,"specialty":81,"image":82,"link":83},"Arian Sabaghi","Weakly-supervised object localization","arian.jpg","https://scholar.google.com/citations?user=xEsTYSQAAAAJ&hl=en","src/content/people/arian.json","39fb02e641effa9c","publications",["Map",88,89,99,100,110,111,123,124,134,135,145,146,156,157,166,167,177,178,188,189,198,199,207,208,219,220,229,230,240,241,249,250,260,261,271,272,281,282,292,293],"action-recognition",{"id":88,"data":90,"filePath":97,"digest":98},{"title":91,"date":92,"conference":93,"tags":94,"link":95,"image":17,"description":96},"Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector","2024/02/27","VISAPP'24",[],"https://repository.uantwerpen.be/docman/irua/3d6ebamotoMe4","This study investigates the applicability of established action recognition methodologies in the dynamic setting of the construction sector.","src/content/publications/action-recognition.json","668528a1c5a528ca","arabic-absa",{"id":99,"data":101,"filePath":108,"digest":109},{"title":102,"date":103,"conference":104,"tags":105,"link":106,"image":55,"description":107},"Gated Recurrent Unit with Multilingual Universal Sentence Encoder for Arabic Aspect-Based Sentiment Analysis","2023/02/01","Knowledge Based Systems",[],"https://www.sciencedirect.com/science/article/pii/S0950705122007300","This study presents a deep learning model for Arabic Aspect-Based Sentiment Analysis (ABSA) using Gated Recurrent Units (GRU) combined with features from the Multilingual Universal Sentence Encoder (MUSE)","src/content/publications/arabic-absa.json","e78342a5e030c749","bilinear-autoencoders",{"id":110,"data":112,"filePath":121,"digest":122},{"title":113,"date":114,"conference":115,"tags":116,"link":119,"image":73,"description":120},"Finding manifolds with bilinear autoencoders","2025/10/01","NeurIPS'25",[117,118],"spotlight","workshop","https://www.arxiv.org/pdf/2510.16820","Decomposing activations into sparse polynomials and using their geometry","src/content/publications/bilinear-autoencoders.json","070632f83d3b8ac1","bilinear-mlps",{"id":123,"data":125,"filePath":132,"digest":133},{"title":126,"date":127,"conference":128,"tags":129,"link":130,"image":73,"description":131},"Bilinear MLPs enable weight-based mechanistic interpretability","2024/10/01","ICLR'25",[117],"https://tdooms.github.io/research/bilinear","Using bilinear MLPs to reverse-engineer shallow MNIST and Tiny Stories models from their weights.","src/content/publications/bilinear-mlps.json","7816394688a86612","capsnet-representations",{"id":134,"data":136,"filePath":143,"digest":144},{"title":137,"date":138,"conference":139,"tags":140,"link":141,"image":55,"description":142},"Towards the Characterization of Representations Learned via Capsule-Based Network Architectures","2025/02/01","Neurocomputing",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231224017983","This paper provides a systematic and principled study on the interpretability of Capsule Network (CapsNet) representations, aiming to characterize the nature and structure of the learned features across diverse architectures and datasets","src/content/publications/capsnet-representations.json","ea4312975d82c3d0","coherence-explanations",{"id":145,"data":147,"filePath":154,"digest":155},{"title":148,"date":149,"conference":150,"tags":151,"link":152,"image":17,"description":153},"On the coherency of quantitative evaluation of visual explanations","2024/04/01","CVIU vol. 241",[],"https://doi.org/10.1016/j.cviu.2024.103934","Measuring the correlation between different quantitative evaluation metrics for visual explanations.","src/content/publications/coherence-explanations.json","da31296bc8404f3d","compositionality",{"id":156,"data":158,"filePath":164,"digest":165},{"title":159,"date":160,"conference":161,"tags":162,"image":73,"description":163},"Compositionality unlocks deep interpretable models","2024/12/01","AAAI'25",[118],"Introducing a global SVD-like algorithm for multi-linear models.","src/content/publications/compositionality.json","dc581920f7142f6c","hsi-contrastive",{"id":166,"data":168,"filePath":175,"digest":176},{"title":169,"date":170,"conference":171,"tags":172,"link":173,"image":64,"description":174},"A Contrastive Learning Method for Multi-Label Predictors on Hyperspectral Images","2024/02/01","WHISPERS",[],"https://doi.org/10.1109/WHISPERS61460.2023.10430726","Self-supervised contrastive learning for multi-label hyperspectral image classification","src/content/publications/hsi-contrastive.json","00db7829eb1f33b9","hsi-multilabel",{"id":177,"data":179,"filePath":186,"digest":187},{"title":180,"date":181,"conference":182,"tags":183,"link":184,"image":64,"description":185},"Training Methods of Multi-Label Prediction Classifiers for Hyperspectral Remote Sensing Images","2023/12/01","Remote Sensing",[],"https://doi.org/10.3390/rs15245656","A deep learning model for hyperspectral remote sensing, shifting from traditional single-label, pixel-level classification to multi-label, patch-level analysis","src/content/publications/hsi-multilabel.json","1a90715870c35626","matrix-capsnet",{"id":188,"data":190,"filePath":196,"digest":197},{"title":191,"date":138,"conference":192,"tags":193,"link":194,"image":55,"description":195},"Analyzing the Explanation and Interpretation Potential of Matrix Capsule Networks","ECML-PKDD",[118],"https://link.springer.com/chapter/10.1007/978-3-031-74630-7_5#citeas","This study investigates the internal mechanisms of Matrix Capsule Networks with the EM Routing algorithm","src/content/publications/matrix-capsnet.json","c318782d8e07431d","model-compression",{"id":198,"data":200,"filePath":205,"digest":206},{"title":201,"date":92,"conference":93,"tags":202,"link":203,"image":17,"description":204},"Deep learning model compression for resource efficient activity recognition on edge devices: a case study",[],"https://repository.uantwerpen.be/docman/irua/666490motoM98","This paper presents an approach to adapt an existing activity recognition model for efficient deployment on edge devices.","src/content/publications/model-compression.json","686d35973cb60458","radio-fingerprint",{"id":207,"data":209,"filePath":217,"digest":218},{"title":210,"date":211,"conference":212,"tags":213,"link":214,"image":215,"description":216},"Label-efficient learning for radio frequency fingerprint identification","2025/03/01","IEEE WCNC'25",[],"https://ieeexplore.ieee.org/abstract/document/10978444","fabian.jpg","We introduce a label-efficient approach for Radio Frequency Fingerprint Identification, achieving competitive accuracy with up to 10x fewer labels.","src/content/publications/radio-fingerprint.json","342b2c99bcf6afce","simplestories",{"id":219,"data":221,"filePath":227,"digest":228},{"title":222,"date":223,"conference":115,"tags":224,"link":225,"image":73,"description":226},"Parameterized Synthetic Text Generation with SimpleStories","2025/11/01",[],"https://openreview.net/pdf?id=sVh3eQ642W","A dataset full of simple yet diverse stories; the MNIST for language","src/content/publications/simplestories.json","1a094b6629126a32","smooth-infomax",{"id":229,"data":231,"filePath":238,"digest":239},{"title":232,"date":233,"conference":234,"tags":235,"link":236,"image":215,"description":237},"Smooth InfoMax - Towards Easier Post-Hoc Interpretability","2025/09/01","ECML-PKDD'25",[],"https://arxiv.org/abs/2408.12936","SIM makes post-hoc interpretability tools more effective through latent space constraints","src/content/publications/smooth-infomax.json","ecf8843894302409","taxonomy-capsnet",{"id":240,"data":242,"filePath":247,"digest":248},{"title":243,"date":223,"conference":139,"tags":244,"link":245,"image":55,"description":246},"A Taxonomy of Interpretation and Explanation Methods for Capsule Network Architectures",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231225026979","This paper presents a comprehensive taxonomy of interpretation and explanation methods developed for Capsule Network (CapsNet) architectures, analyzing their mechanisms, applicability, and performance across diverse problem domains.","src/content/publications/taxonomy-capsnet.json","2a8ca3126666da83","tokenized-saes",{"id":249,"data":251,"filePath":258,"digest":259},{"title":252,"date":253,"conference":254,"tags":255,"link":256,"image":73,"description":257},"Tokenized SAEs: Disentangling SAE Reconstructions","2024/06/01","ICML'24",[118],"https://tdooms.github.io/research/tokenized","We use a per-token bias in SAEs to separate token reconstructions from interesting features.","src/content/publications/tokenized-saes.json","f5689c0034819c63","trifecta",{"id":260,"data":262,"filePath":269,"digest":270},{"title":263,"date":264,"conference":265,"tags":266,"link":267,"image":73,"description":268},"The Trifecta: Three techniques for deeper Forward-Forward networks","2023/11/01","TMLR",[],"https://tdooms.github.io/research/trifecta","Three techniques to significantly improve the Forward-Forward algorithm. We achieve 84% on CIFAR-10.","src/content/publications/trifecta.json","828a58fc61fa6322","twin-network-cnn",{"id":271,"data":273,"filePath":279,"digest":280},{"title":274,"date":275,"conference":128,"tags":276,"link":277,"image":17,"description":278},"Improving neural network accuracy by concurrently training with a twin network","2025/04/01",[],"https://openreview.net/forum?id=TEmE9PSC65","We show the applicability of twin network augmentation on convolutional neural networks","src/content/publications/twin-network-cnn.json","0d376d92ff975f98","twin-network-snn",{"id":281,"data":283,"filePath":290,"digest":291},{"title":284,"date":285,"conference":286,"tags":287,"link":288,"image":17,"description":289},"Twin Network Augmentation","2024/09/01","arXiv",[],"https://arxiv.org/pdf/2409.15849","A Novel Training Strategy for Improved Spiking Neural Networks and Efficient Weight Quantization.","src/content/publications/twin-network-snn.json","eb8ff15a76ecebbd","weight-based-decomposition",{"id":292,"data":294,"filePath":298,"digest":299},{"title":295,"date":253,"conference":254,"tags":296,"link":130,"image":73,"description":297},"Weight-based Decomposition: A Case for Bilinear MLPs",[118],"Introducing bilinear MLPs as a new approach to weight-based interpretability.","src/content/publications/weight-based-decomposition.json","f81a5cdaefd2f9de","events",["Map",302,303,311,312,319,320,327,328,336,337,345,346,354,355,363,364,372,373,381,382,389,390],"acrai-research-day",{"id":302,"data":304,"filePath":309,"digest":310},{"title":305,"date":306,"link":307,"image":64,"description":308},"Talk @ ACRAI Research Day","2025/02/21","https://www.uantwerpen.be/en/research-groups/acrai/","Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging","src/content/events/acrai-research-day.json","43c3f298c9329f0c","becode",{"id":311,"data":313,"filePath":317,"digest":318},{"title":314,"date":127,"link":315,"image":55,"description":316},"Talk @ BeCode","https://becode.org/","General presentation about explainability","src/content/events/becode.json","b704f32d0e63c0d0","clusity",{"id":319,"data":321,"filePath":325,"digest":326},{"title":322,"date":323,"link":324,"image":55,"description":316},"Talk @ Clusity","2023/06/01","https://www.clusity.be/","src/content/events/clusity.json","268cb0d7cd2ba870","dataset-distillation-vaia",{"id":327,"data":329,"filePath":334,"digest":335},{"title":330,"date":331,"link":332,"image":17,"description":333},"Webinar@Dataset Distillation - A Gentle Introduction","2025/07/15","https://www.vaia.be/en/courses/dataset-distillation-a-gentle-introduction","Get familiar with the standard dataset distillation techniques, and gain familiarity with uses cases that could benefit from it.","src/content/events/dataset-distillation-vaia.json","7f6e4e2768feca5e","efficientml",{"id":336,"data":338,"filePath":343,"digest":344},{"title":339,"date":340,"link":341,"image":17,"description":342},"Talk@Efficient ML Reading Group","2025/06/30","https://www.youtube.com/watch?v=rB2_SZIQUd0","Twin Network Augmentation for Convolutional Neural Networks.","src/content/events/efficientml.json","344416d884bcffd7","flanders-ai-2023",{"id":345,"data":347,"filePath":352,"digest":353},{"title":348,"date":349,"link":350,"image":17,"description":351},"Talk@Flanders AI Day - Workshop on Advances in Responsible AI","2023/10/16","https://www.flandersairesearch.be/en/research/research-day","Presentation on coherence between different evaluation metrics for visual explanations.","src/content/events/flanders-ai-2023.json","29f853d0238d6a70","flanders-ai-day",{"id":354,"data":356,"filePath":361,"digest":362},{"title":357,"date":358,"link":359,"image":73,"description":360},"Talk @ Flanders AI Day","2024/10/14","https://docs.google.com/presentation/d/1PdcHm0bgwIu3yhy6oWkwL1-fDGTPzTiyUilydognLlw/edit?usp=sharing","A swift introduction to weight-based interpretability.","src/content/events/flanders-ai-day.json","06b5b0d7783a0ace","kekule-cycle",{"id":363,"data":365,"filePath":370,"digest":371},{"title":366,"date":367,"link":368,"image":27,"description":369},"Talk @ Kekule Cycle XXI","2025/10/14","https://www.kvcv.be/nl/activiteiten-en-nieuws/kalender/676-quid-quantum-and-ai","An accessible introduction to representation learning and interpretability","src/content/events/kekule-cycle.json","5989a88e73d4f3db","vaia-webinar",{"id":372,"data":374,"filePath":379,"digest":380},{"title":375,"date":376,"link":377,"image":64,"description":378},"Webinar @ VAIA - Flanders AI EDIH HSI Talk","2025/09/29","https://www.vaia.be/","Hyperspectral Imaging and Machine Learning: Decoding the Spectrum for Advanced Data Analysis","src/content/events/vaia-webinar.json","70b281a9490e6153","visapp24",{"id":381,"data":383,"filePath":387,"digest":388},{"title":384,"date":92,"link":385,"image":17,"description":386},"Talk @ VisAPP'24","https://visapp.scitevents.org/","Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector.","src/content/events/visapp24.json","fed64b813f0b8092","wids",{"id":389,"data":391,"filePath":396,"digest":397},{"title":392,"date":393,"link":394,"image":55,"description":395},"Talk @ Women in Data Science (WiDS)","2024/03/01","https://www.widsconference.org/","Analyzing Representations Learned via Capsule Neural Networks. A systematic and principled study towards assessing the interpretability of Capsule networks","src/content/events/wids.json","934141e8fa1868c5","news",["Map",400,401,407,408,414,415,421,422,430,431,437,438,444,445,451,452,458,459,465,466],"2024-03-wids",{"id":400,"data":402,"filePath":405,"digest":406},{"date":393,"title":403,"description":404},"Event","Co-organized a Women in Data event.","src/content/news/2024-03-wids.json","5f73b4a7faa959ae","2024-09-workshop",{"id":407,"data":409,"filePath":412,"digest":413},{"date":285,"title":410,"description":411},"Workshop","Co-organized the AIMLAI Workshop held in conjunction with ECML-PKDD'24.","src/content/news/2024-09-workshop.json","7e2ee729f377a06a","2024-10-peter",{"id":414,"data":416,"filePath":419,"digest":420},{"date":127,"title":417,"description":418},"New member","sqIRL welcomes Peter to the lab.","src/content/news/2024-10-peter.json","1cf43d89dbfe72a9","2024-10-tmlr",{"id":421,"data":423,"filePath":428,"digest":429},{"date":424,"title":425,"description":426,"link":427},"2024/10/02","Paper accepted","Thomas' work on deeper forward-forward networks got published at TMLR.","https://openreview.net/forum?id=a7KP5uo0Fp","src/content/news/2024-10-tmlr.json","14183511984ccb85","2024-12-neurocomputing",{"id":430,"data":432,"filePath":435,"digest":436},{"date":160,"title":425,"description":433,"link":434},"Saja's paper on the interpretability of Capsule Networks was accepted at the journal of Neurocomputing.","https://arxiv.org/abs/2305.05349","src/content/news/2024-12-neurocomputing.json","3cfb1c6745a2798b","2025-01-iclr",{"id":437,"data":439,"filePath":442,"digest":443},{"date":440,"title":425,"description":441},"2025/01/01","Two papers accepted at ICLR'25 on Twin Network Augmentation and Interpretability via Bilinear MLPs.","src/content/news/2025-01-iclr.json","39e899cda47d4191","2025-06-ecml",{"id":444,"data":446,"filePath":449,"digest":450},{"date":447,"title":425,"description":448},"2025/06/01","Two papers accepted at ECML-PKDD'25 on Smooth-InfoMax and Interpretability of SNNs.","src/content/news/2025-06-ecml.json","1aec7e1098ae188d","2025-09-renata",{"id":451,"data":453,"filePath":456,"digest":457},{"date":233,"title":417,"description":454,"link":455},"sqIRL welcomes Renata to the lab.","https://renata-turkes.github.io/","src/content/news/2025-09-renata.json","d19570370e7284c3","2025-10-neurocomputing-hdc",{"id":458,"data":460,"filePath":463,"digest":464},{"date":114,"title":425,"description":461,"link":462},"One paper accepted at Neurocomputing on Interpretable HDC Classifiers.","https://doi.org/10.1016/j.neucom.2025.131643","src/content/news/2025-10-neurocomputing-hdc.json","02a93ace17aa8479","2025-11-neurocomputing",{"id":465,"data":467,"filePath":469,"digest":470},{"date":223,"title":425,"description":468,"link":245},"Saja's paper on positioning a taxonomy of interpretation and explanation methods for Capsule Networks was accepted in the journal Neurocomputing.","src/content/news/2025-11-neurocomputing.json","9aa17e92db1f2ddb","home",["Map",473,474],"main",{"id":473,"data":475,"filePath":481,"digest":482},{"title":476,"subtitle":477,"description":478,"email":479,"logo":480},"sqIRL","Interpretable Representation Learning","The Interpretable Representation Learning lab, sqIRL, at the University of Antwerp pursues fundamental research at the intersection of machine learning and interpretability/explainability. Our research focuses on the inner-workings of AI systems and the learning processes that produce them. We aim to develop AI systems that are interpretable/explainable and more efficient in their use of data and computational resources.","jose.oramasmogrovejo@uantwerpen.be","/logo.png","src/content/home/main.json","64c87d672340e3cb"]