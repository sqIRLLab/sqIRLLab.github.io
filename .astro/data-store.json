[["Map",1,2,9,10,86,87,319,320,417,418,489,490],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.2","content-config-digest","e85c5da6148dd422","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://sqirllab.github.io\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","people",["Map",11,12,21,22,31,32,40,41,50,51,59,60,68,69,77,78],"benjamin",{"id":11,"data":13,"filePath":19,"digest":20},{"name":14,"status":15,"specialty":16,"image":17,"link":18},"Benjamin Vandersmissen","PhD student","Representations and lottery ticket hypothesis","benjamin.jpg","https://scholar.google.com/citations?user=pfgVNMUAAAAJ&hl=en","src/content/people/benjamin.json","5463b1cb0277467e","jose",{"id":21,"data":23,"filePath":29,"digest":30},{"name":24,"status":25,"specialty":26,"image":27,"link":28},"Jose Oramas","Professor","Representation Learning and Interpretability","jose.png","https://idlab.uantwerpen.be/~joramasmogrovejo/","src/content/people/jose.json","422a134df86afd3b","peter",{"id":31,"data":33,"filePath":38,"digest":39},{"name":34,"status":15,"specialty":35,"image":36,"link":37},"Peter Kirby","Binary hyperdimensional computing","peter.jpg","https://www.uantwerpen.be/en/staff/peter-kirby_27404/","src/content/people/peter.json","89803df955ca2798","renata",{"id":40,"data":42,"filePath":48,"digest":49},{"name":43,"status":44,"specialty":45,"image":46,"link":47},"Renata Turke≈°","Postdoctoral researcher","Topological data analysis","renata.png","https://renata-turkes.github.io","src/content/people/renata.json","31038571fc01c248","saja",{"id":50,"data":52,"filePath":57,"digest":58},{"name":53,"status":15,"specialty":54,"image":55,"link":56},"Saja Tawalbeh","Explainable artificial intelligence","saja.png","https://stawalbeh.github.io/STawalbeh/","src/content/people/saja.json","7b704b9f71cf27e7","salma",{"id":59,"data":61,"filePath":66,"digest":67},{"name":62,"status":15,"specialty":63,"image":64,"link":65},"Salma Haidar","Hyperspectral image analysis","salma.jpg","https://www.salmahaidar.com/","src/content/people/salma.json","86f015ffd9df6b48","thomas",{"id":68,"data":70,"filePath":75,"digest":76},{"name":71,"status":15,"specialty":72,"image":73,"link":74},"Thomas Dooms","Weight-based interpretability","thomas.jpg","https://tdooms.github.io/","src/content/people/thomas.json","172ff8224d2951fd","arian",{"id":77,"data":79,"filePath":84,"digest":85},{"name":80,"status":15,"specialty":81,"image":82,"link":83},"Arian Sabaghi","Weakly-supervised object localization","arian.jpg","https://scholar.google.com/citations?user=xEsTYSQAAAAJ&hl=en","src/content/people/arian.json","39fb02e641effa9c","publications",["Map",88,89,99,100,110,111,123,124,134,135,145,146,156,157,166,167,177,178,188,189,199,200,208,209,220,221,230,231,241,242,250,251,261,262,272,273,282,283,293,294,301,302,310,311],"action-recognition",{"id":88,"data":90,"filePath":97,"digest":98},{"title":91,"date":92,"conference":93,"tags":94,"link":95,"image":17,"description":96},"Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector","2024/02/27","VISAPP'24",[],"https://repository.uantwerpen.be/docman/irua/3d6ebamotoMe4","This study investigates the applicability of established action recognition methodologies in the dynamic setting of the construction sector.","src/content/publications/action-recognition.json","668528a1c5a528ca","arabic-absa",{"id":99,"data":101,"filePath":108,"digest":109},{"title":102,"date":103,"conference":104,"tags":105,"link":106,"image":55,"description":107},"Gated Recurrent Unit with Multilingual Universal Sentence Encoder for Arabic Aspect-Based Sentiment Analysis","2023/02/01","Knowledge Based Systems",[],"https://www.sciencedirect.com/science/article/pii/S0950705122007300","This study presents a deep learning model for Arabic Aspect-Based Sentiment Analysis (ABSA) using Gated Recurrent Units (GRU) combined with features from the Multilingual Universal Sentence Encoder (MUSE)","src/content/publications/arabic-absa.json","e78342a5e030c749","bilinear-autoencoders",{"id":110,"data":112,"filePath":121,"digest":122},{"title":113,"date":114,"conference":115,"tags":116,"link":119,"image":73,"description":120},"Finding manifolds with bilinear autoencoders","2025/10/01","NeurIPS'25",[117,118],"spotlight","workshop","https://www.arxiv.org/pdf/2510.16820","Decomposing activations into sparse polynomials and using their geometry","src/content/publications/bilinear-autoencoders.json","070632f83d3b8ac1","bilinear-mlps",{"id":123,"data":125,"filePath":132,"digest":133},{"title":126,"date":127,"conference":128,"tags":129,"link":130,"image":73,"description":131},"Bilinear MLPs enable weight-based mechanistic interpretability","2024/10/01","ICLR'25",[117],"https://tdooms.github.io/research/bilinear","Using bilinear MLPs to reverse-engineer shallow MNIST and Tiny Stories models from their weights.","src/content/publications/bilinear-mlps.json","7816394688a86612","capsnet-representations",{"id":134,"data":136,"filePath":143,"digest":144},{"title":137,"date":138,"conference":139,"tags":140,"link":141,"image":55,"description":142},"Towards the Characterization of Representations Learned via Capsule-Based Network Architectures","2025/02/01","Neurocomputing",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231224017983","This paper provides a systematic and principled study on the interpretability of Capsule Network (CapsNet) representations, aiming to characterize the nature and structure of the learned features across diverse architectures and datasets","src/content/publications/capsnet-representations.json","ea4312975d82c3d0","coherence-explanations",{"id":145,"data":147,"filePath":154,"digest":155},{"title":148,"date":149,"conference":150,"tags":151,"link":152,"image":17,"description":153},"On the coherency of quantitative evaluation of visual explanations","2024/04/01","CVIU vol. 241",[],"https://doi.org/10.1016/j.cviu.2024.103934","Measuring the correlation between different quantitative evaluation metrics for visual explanations.","src/content/publications/coherence-explanations.json","da31296bc8404f3d","compositionality",{"id":156,"data":158,"filePath":164,"digest":165},{"title":159,"date":160,"conference":161,"tags":162,"image":73,"description":163},"Compositionality unlocks deep interpretable models","2024/12/01","AAAI'25",[118],"Introducing a global SVD-like algorithm for multi-linear models.","src/content/publications/compositionality.json","dc581920f7142f6c","hsi-contrastive",{"id":166,"data":168,"filePath":175,"digest":176},{"title":169,"date":170,"conference":171,"tags":172,"link":173,"image":64,"description":174},"A Contrastive Learning Method for Multi-Label Predictors on Hyperspectral Images","2024/02/01","WHISPERS",[],"https://doi.org/10.1109/WHISPERS61460.2023.10430726","Self-supervised contrastive learning for multi-label hyperspectral image classification","src/content/publications/hsi-contrastive.json","00db7829eb1f33b9","hsi-multilabel",{"id":177,"data":179,"filePath":186,"digest":187},{"title":180,"date":181,"conference":182,"tags":183,"link":184,"image":64,"description":185},"Training Methods of Multi-Label Prediction Classifiers for Hyperspectral Remote Sensing Images","2023/12/01","Remote Sensing",[],"https://doi.org/10.3390/rs15245656","A deep learning model for hyperspectral remote sensing, shifting from traditional single-label, pixel-level classification to multi-label, patch-level analysis","src/content/publications/hsi-multilabel.json","1a90715870c35626","matrix-capsnet",{"id":188,"data":190,"filePath":197,"digest":198},{"title":191,"date":192,"conference":193,"tags":194,"link":195,"image":55,"description":196},"Analyzing the Explanation and Interpretation Potential of Matrix Capsule Networks","2023/09/01","ECML-PKDD'23",[118],"https://link.springer.com/chapter/10.1007/978-3-031-74630-7_5#citeas","A look into the internal mechanisms of Matrix CapNets with EM Routing","src/content/publications/matrix-capsnet.json","31ad0bac216d7179","model-compression",{"id":199,"data":201,"filePath":206,"digest":207},{"title":202,"date":92,"conference":93,"tags":203,"link":204,"image":17,"description":205},"Deep learning model compression for resource efficient activity recognition on edge devices: a case study",[],"https://repository.uantwerpen.be/docman/irua/666490motoM98","This paper presents an approach to adapt an existing activity recognition model for efficient deployment on edge devices.","src/content/publications/model-compression.json","686d35973cb60458","radio-fingerprint",{"id":208,"data":210,"filePath":218,"digest":219},{"title":211,"date":212,"conference":213,"tags":214,"link":215,"image":216,"description":217},"Label-efficient learning for radio frequency fingerprint identification","2025/03/01","IEEE WCNC'25",[],"https://ieeexplore.ieee.org/abstract/document/10978444","fabian.jpg","We introduce a label-efficient approach for Radio Frequency Fingerprint Identification, achieving competitive accuracy with up to 10x fewer labels.","src/content/publications/radio-fingerprint.json","342b2c99bcf6afce","simplestories",{"id":220,"data":222,"filePath":228,"digest":229},{"title":223,"date":224,"conference":115,"tags":225,"link":226,"image":73,"description":227},"Parameterized Synthetic Text Generation with SimpleStories","2025/11/01",[],"https://openreview.net/pdf?id=sVh3eQ642W","A dataset full of simple yet diverse stories; the MNIST for language","src/content/publications/simplestories.json","1a094b6629126a32","smooth-infomax",{"id":230,"data":232,"filePath":239,"digest":240},{"title":233,"date":234,"conference":235,"tags":236,"link":237,"image":216,"description":238},"Smooth InfoMax - Towards Easier Post-Hoc Interpretability","2025/09/01","ECML-PKDD'25",[],"https://arxiv.org/abs/2408.12936","SIM makes post-hoc interpretability tools more effective through latent space constraints","src/content/publications/smooth-infomax.json","ecf8843894302409","taxonomy-capsnet",{"id":241,"data":243,"filePath":248,"digest":249},{"title":244,"date":224,"conference":139,"tags":245,"link":246,"image":55,"description":247},"A Taxonomy of Interpretation and Explanation Methods for Capsule Network Architectures",[],"https://www.sciencedirect.com/science/article/abs/pii/S0925231225026979","This paper presents a comprehensive taxonomy of interpretation and explanation methods developed for Capsule Network (CapsNet) architectures, analyzing their mechanisms, applicability, and performance across diverse problem domains.","src/content/publications/taxonomy-capsnet.json","2a8ca3126666da83","tokenized-saes",{"id":250,"data":252,"filePath":259,"digest":260},{"title":253,"date":254,"conference":255,"tags":256,"link":257,"image":73,"description":258},"Tokenized SAEs: Disentangling SAE Reconstructions","2024/06/01","ICML'24",[118],"https://tdooms.github.io/research/tokenized","We use a per-token bias in SAEs to separate token reconstructions from interesting features.","src/content/publications/tokenized-saes.json","f5689c0034819c63","trifecta",{"id":261,"data":263,"filePath":270,"digest":271},{"title":264,"date":265,"conference":266,"tags":267,"link":268,"image":73,"description":269},"The Trifecta: Three techniques for deeper Forward-Forward networks","2023/11/01","TMLR",[],"https://tdooms.github.io/research/trifecta","Three techniques to significantly improve the Forward-Forward algorithm. We achieve 84% on CIFAR-10.","src/content/publications/trifecta.json","828a58fc61fa6322","twin-network-cnn",{"id":272,"data":274,"filePath":280,"digest":281},{"title":275,"date":276,"conference":128,"tags":277,"link":278,"image":17,"description":279},"Improving neural network accuracy by concurrently training with a twin network","2025/04/01",[],"https://openreview.net/forum?id=TEmE9PSC65","We show the applicability of twin network augmentation on convolutional neural networks","src/content/publications/twin-network-cnn.json","0d376d92ff975f98","twin-network-snn",{"id":282,"data":284,"filePath":291,"digest":292},{"title":285,"date":286,"conference":287,"tags":288,"link":289,"image":17,"description":290},"Twin Network Augmentation","2024/09/01","arXiv",[],"https://arxiv.org/pdf/2409.15849","A Novel Training Strategy for Improved Spiking Neural Networks and Efficient Weight Quantization.","src/content/publications/twin-network-snn.json","eb8ff15a76ecebbd","weight-based-decomposition",{"id":293,"data":295,"filePath":299,"digest":300},{"title":296,"date":254,"conference":255,"tags":297,"link":130,"image":73,"description":298},"Weight-based Decomposition: A Case for Bilinear MLPs",[118],"Introducing bilinear MLPs as a new approach to weight-based interpretability.","src/content/publications/weight-based-decomposition.json","f81a5cdaefd2f9de","svebi",{"id":301,"data":303,"filePath":308,"digest":309},{"title":304,"date":234,"conference":235,"tags":305,"link":306,"image":27,"description":307},"SVEBI: Towards the Interpretation and Explanation of Spiking Neural Networks",[],"https://link.springer.com/chapter/10.1007/978-3-032-06066-2_27","A posthoc explanation method for spiking neural networks","src/content/publications/svebi.json","54bb53a80b57b6a6","hdc-interpretability",{"id":310,"data":312,"filePath":317,"digest":318},{"title":313,"date":114,"conference":139,"tags":314,"link":315,"image":27,"description":316},"Explaining and interpreting hyperdimensional computing classifiers on tabular data",[],"https://doi.org/10.1016/j.neucom.2025.131643","We make HDC classifiers for tabular data more interpretable","src/content/publications/hdc-interpretability.json","b9ccabdd3003e59a","events",["Map",321,322,330,331,338,339,346,347,355,356,364,365,373,374,382,383,391,392,400,401,408,409],"acrai-research-day",{"id":321,"data":323,"filePath":328,"digest":329},{"title":324,"date":325,"link":326,"image":64,"description":327},"Talk @ ACRAI Research Day","2025/02/21","https://www.uantwerpen.be/en/research-groups/acrai/","Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging","src/content/events/acrai-research-day.json","43c3f298c9329f0c","becode",{"id":330,"data":332,"filePath":336,"digest":337},{"title":333,"date":127,"link":334,"image":55,"description":335},"Talk @ BeCode","https://becode.org/","General presentation about explainability","src/content/events/becode.json","b704f32d0e63c0d0","clusity",{"id":338,"data":340,"filePath":344,"digest":345},{"title":341,"date":342,"link":343,"image":55,"description":335},"Talk @ Clusity","2023/06/01","https://www.clusity.be/","src/content/events/clusity.json","268cb0d7cd2ba870","dataset-distillation-vaia",{"id":346,"data":348,"filePath":353,"digest":354},{"title":349,"date":350,"link":351,"image":17,"description":352},"Webinar@Dataset Distillation - A Gentle Introduction","2025/07/15","https://www.vaia.be/en/courses/dataset-distillation-a-gentle-introduction","Get familiar with the standard dataset distillation techniques, and gain familiarity with uses cases that could benefit from it.","src/content/events/dataset-distillation-vaia.json","7f6e4e2768feca5e","efficientml",{"id":355,"data":357,"filePath":362,"digest":363},{"title":358,"date":359,"link":360,"image":17,"description":361},"Talk@Efficient ML Reading Group","2025/06/30","https://www.youtube.com/watch?v=rB2_SZIQUd0","Twin Network Augmentation for Convolutional Neural Networks.","src/content/events/efficientml.json","344416d884bcffd7","flanders-ai-2023",{"id":364,"data":366,"filePath":371,"digest":372},{"title":367,"date":368,"link":369,"image":17,"description":370},"Talk@Flanders AI Day - Workshop on Advances in Responsible AI","2023/10/16","https://www.flandersairesearch.be/en/research/research-day","Presentation on coherence between different evaluation metrics for visual explanations.","src/content/events/flanders-ai-2023.json","29f853d0238d6a70","flanders-ai-day",{"id":373,"data":375,"filePath":380,"digest":381},{"title":376,"date":377,"link":378,"image":73,"description":379},"Talk @ Flanders AI Day","2024/10/14","https://docs.google.com/presentation/d/1PdcHm0bgwIu3yhy6oWkwL1-fDGTPzTiyUilydognLlw/edit?usp=sharing","A swift introduction to weight-based interpretability.","src/content/events/flanders-ai-day.json","06b5b0d7783a0ace","kekule-cycle",{"id":382,"data":384,"filePath":389,"digest":390},{"title":385,"date":386,"link":387,"image":27,"description":388},"Talk @ Kekule Cycle XXI","2025/10/14","https://www.kvcv.be/nl/activiteiten-en-nieuws/kalender/676-quid-quantum-and-ai","An accessible introduction to representation learning and interpretability","src/content/events/kekule-cycle.json","5989a88e73d4f3db","vaia-webinar",{"id":391,"data":393,"filePath":398,"digest":399},{"title":394,"date":395,"link":396,"image":64,"description":397},"Webinar @ VAIA - Flanders AI EDIH HSI Talk","2025/09/29","https://www.vaia.be/","Hyperspectral Imaging and Machine Learning: Decoding the Spectrum for Advanced Data Analysis","src/content/events/vaia-webinar.json","70b281a9490e6153","visapp24",{"id":400,"data":402,"filePath":406,"digest":407},{"title":403,"date":92,"link":404,"image":17,"description":405},"Talk @ VisAPP'24","https://visapp.scitevents.org/","Recognizing actions in high-resolution low-framerate videos: a feasibility study in the construction sector.","src/content/events/visapp24.json","fed64b813f0b8092","wids",{"id":408,"data":410,"filePath":415,"digest":416},{"title":411,"date":412,"link":413,"image":55,"description":414},"Talk @ Women in Data Science (WiDS)","2024/03/01","https://www.widsconference.org/","Analyzing Representations Learned via Capsule Neural Networks. A systematic and principled study towards assessing the interpretability of Capsule networks","src/content/events/wids.json","934141e8fa1868c5","news",["Map",419,420,426,427,433,434,440,441,449,450,456,457,463,464,470,471,477,478,483,484],"2024-03-wids",{"id":419,"data":421,"filePath":424,"digest":425},{"date":412,"title":422,"description":423},"Event","Co-organized a Women in Data event.","src/content/news/2024-03-wids.json","5f73b4a7faa959ae","2024-09-workshop",{"id":426,"data":428,"filePath":431,"digest":432},{"date":286,"title":429,"description":430},"Workshop","Co-organized the AIMLAI Workshop held in conjunction with ECML-PKDD'24.","src/content/news/2024-09-workshop.json","7e2ee729f377a06a","2024-10-peter",{"id":433,"data":435,"filePath":438,"digest":439},{"date":127,"title":436,"description":437},"New member","sqIRL welcomes Peter to the lab.","src/content/news/2024-10-peter.json","1cf43d89dbfe72a9","2024-10-tmlr",{"id":440,"data":442,"filePath":447,"digest":448},{"date":443,"title":444,"description":445,"link":446},"2024/10/02","Paper accepted","Thomas' work on deeper forward-forward networks got published at TMLR.","https://openreview.net/forum?id=a7KP5uo0Fp","src/content/news/2024-10-tmlr.json","14183511984ccb85","2024-12-neurocomputing",{"id":449,"data":451,"filePath":454,"digest":455},{"date":160,"title":444,"description":452,"link":453},"Saja's paper on the interpretability of Capsule Networks was accepted at the journal of Neurocomputing.","https://arxiv.org/abs/2305.05349","src/content/news/2024-12-neurocomputing.json","3cfb1c6745a2798b","2025-01-iclr",{"id":456,"data":458,"filePath":461,"digest":462},{"date":459,"title":444,"description":460},"2025/01/01","Two papers accepted at ICLR'25 on Twin Network Augmentation and Interpretability via Bilinear MLPs.","src/content/news/2025-01-iclr.json","39e899cda47d4191","2025-06-ecml",{"id":463,"data":465,"filePath":468,"digest":469},{"date":466,"title":444,"description":467},"2025/06/01","Two papers accepted at ECML-PKDD'25 on Smooth-InfoMax and Interpretability of SNNs.","src/content/news/2025-06-ecml.json","1aec7e1098ae188d","2025-09-renata",{"id":470,"data":472,"filePath":475,"digest":476},{"date":234,"title":436,"description":473,"link":474},"sqIRL welcomes Renata to the lab.","https://renata-turkes.github.io/","src/content/news/2025-09-renata.json","d19570370e7284c3","2025-10-neurocomputing-hdc",{"id":477,"data":479,"filePath":481,"digest":482},{"date":114,"title":444,"description":480,"link":315},"One paper accepted at Neurocomputing on Interpretable HDC Classifiers.","src/content/news/2025-10-neurocomputing-hdc.json","02a93ace17aa8479","2025-11-neurocomputing",{"id":483,"data":485,"filePath":487,"digest":488},{"date":224,"title":444,"description":486,"link":246},"Saja's paper on positioning a taxonomy of interpretation and explanation methods for Capsule Networks was accepted in the journal Neurocomputing.","src/content/news/2025-11-neurocomputing.json","9aa17e92db1f2ddb","home",["Map",491,492],"main",{"id":491,"data":493,"filePath":499,"digest":500},{"title":494,"subtitle":495,"description":496,"email":497,"logo":498},"sqIRL","Interpretable Representation Learning","The Interpretable Representation Learning lab, sqIRL, at the University of Antwerp pursues fundamental research at the intersection of machine learning and interpretability/explainability. Our research focuses on the inner-workings of AI systems and the learning processes that produce them. We aim to develop AI systems that are interpretable/explainable and more efficient in their use of data and computational resources.","jose.oramasmogrovejo@uantwerpen.be","/logo.png","src/content/home/main.json","64c87d672340e3cb"]