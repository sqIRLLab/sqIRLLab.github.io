import{f,a as u}from"../chunks/BVKn8-tb.js";import"../chunks/BpDx7vxY.js";import{c as a,r as i,s as p,t as w,f as k,g as x}from"../chunks/FtJ1th04.js";import{e as I,i as _}from"../chunks/U8mfz1Jo.js";import{p as l,s as L}from"../chunks/dvRKkLBq.js";import{N}from"../chunks/DqzKu2qT.js";import{s as v}from"../chunks/BKPS843G.js";import{a as y}from"../chunks/9UOpuU56.js";var P=f('<a class="box"><small> </small> <p><b> </b></p></a>');function A(c,e){let r=l(e,"link",8),n=l(e,"title",8),o=l(e,"date",8),d=l(e,"description",8);var t=P(),s=a(t),b=a(s);i(s);var m=p(s,2),h=a(m),g=a(h,!0);i(h),i(m),i(t),w(()=>{y(t,"href",r()),v(b,`${n()??""} | ${o()??""}`),v(g,d())}),u(c,t)}const R=[{date:"Jan 2025",title:"Paper accepted",description:"Two papers accepted at ICLR'25 on Twin Network Augmentation and Interpretability via Bilinear MLPs.",link:""},{date:"Dec 2024",title:"Paper accepted",description:"Saja's paper on the interpretability of Capsule Networks was accepted at the journal of Neurocomputing.",link:"https://arxiv.org/abs/2305.05349"},{date:"Oct 2024",title:"Paper accepted",description:"Thomas' work on deeper forward-forward networks got published at TMLR.",link:"https://openreview.net/forum?id=a7KP5uo0Fp"},{date:"Oct 2024",title:"New member",description:"sqIRL welcomes Peter to the lab.",link:""},{date:"Sep 2024",title:"Workshop",description:"Co-organized the AIMLAI Workshop held in conjunction with ECML-PKDD'24.",link:""}];var T=f(`<!> <div class="columns"><div class="column is-3"><div class="box has-text-centered"><figure class="image is-128x128 is-inline-block"><img src="sqirl.png" alt="sqirl"/></figure> <h6 class="subtitle is-6">Interpretable Representation Learning</h6> <hr/> <div class="block"><span class="icon"><i class="fas fa-envelope"></i></span> <span><a href="mailto:doomsthomas@gmail.com">Email</a></span></div></div></div> <div class="column"><div class="box"><div class="content"><p>The Interpretable Representation Learning lab, sqIRL, at the University of Antwerp pursues fundamental research at the intersection of machine learning and interpretability/explainability.
                    Our research focuses on the inner-workings of AI systems and the learning processes that produce them.
                    We aim to develop AI systems that are interpretable/explainable and more efficient in their use of data and computational resources.</p></div></div> <h5 class="title is-5 ml-2 mb-1">News</h5> <!></div></div>`,1);function K(c){var e=T(),r=k(e);N(r,{});var n=p(r,2),o=p(a(n),2),d=p(a(o),4);I(d,1,()=>R,_,(t,s)=>{A(t,L(()=>x(s)))}),i(o),i(n),u(c,e)}export{K as component};
